{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPs2+h3caHNr+ZIj4Toy1Pk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BhumikaAgrawal777/Celebal-Internship/blob/main/Celebal_model_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6nBXzA-u2WYO",
        "outputId": "7af1d94c-5eae-4535-ce3b-cae4187818c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available columns: ['survived', 'pclass', 'sex', 'age', 'sibsp', 'parch', 'fare', 'embarked']\n",
            "✅ Using target column: survived\n",
            "   survived  pclass     sex  age  sibsp  parch    fare embarked\n",
            "0         1       1  female   29      0      0  100.00        S\n",
            "1         0       3    male   22      1      0    7.25        S\n",
            "2         1       2  female   27      0      2   12.35        C\n",
            "3         0       3    male   35      0      0    8.05        S\n",
            "4         1       1  female   54      0      1   51.86        S\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 10 entries, 0 to 9\n",
            "Data columns (total 8 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   survived  10 non-null     int64  \n",
            " 1   pclass    10 non-null     int64  \n",
            " 2   sex       10 non-null     object \n",
            " 3   age       10 non-null     int64  \n",
            " 4   sibsp     10 non-null     int64  \n",
            " 5   parch     10 non-null     int64  \n",
            " 6   fare      10 non-null     float64\n",
            " 7   embarked  10 non-null     object \n",
            "dtypes: float64(1), int64(5), object(2)\n",
            "memory usage: 772.0+ bytes\n",
            "None\n",
            "        survived     pclass       age      sibsp      parch        fare\n",
            "count  10.000000  10.000000  10.00000  10.000000  10.000000   10.000000\n",
            "mean    0.500000   2.200000  27.20000   0.900000   0.500000   28.180000\n",
            "std     0.527046   0.918937  18.57597   1.449138   0.707107   28.698772\n",
            "min     0.000000   1.000000   2.00000   0.000000   0.000000    7.250000\n",
            "25%     0.000000   1.250000  16.00000   0.000000   0.000000    9.125000\n",
            "50%     0.500000   2.500000  27.00000   0.000000   0.000000   18.885000\n",
            "75%     1.000000   3.000000  33.50000   1.000000   1.000000   29.190000\n",
            "max     1.000000   3.000000  58.00000   4.000000   2.000000  100.000000\n",
            "Missing values:\n",
            " survived    0\n",
            "pclass      0\n",
            "sex         0\n",
            "age         0\n",
            "sibsp       0\n",
            "parch       0\n",
            "fare        0\n",
            "embarked    0\n",
            "dtype: int64\n",
            "Duplicates: 0\n",
            "\n",
            "----- Logistic Regression -----\n",
            "Accuracy : 1.0\n",
            "Precision: 0.0\n",
            "Recall   : 0.0\n",
            "F1-score : 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "----- Decision Tree -----\n",
            "Accuracy : 1.0\n",
            "Precision: 0.0\n",
            "Recall   : 0.0\n",
            "F1-score : 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "----- Random Forest -----\n",
            "Accuracy : 1.0\n",
            "Precision: 0.0\n",
            "Recall   : 0.0\n",
            "F1-score : 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "----- SVM -----\n",
            "Accuracy : 1.0\n",
            "Precision: 0.0\n",
            "Recall   : 0.0\n",
            "F1-score : 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "----- Naive Bayes -----\n",
            "Accuracy : 1.0\n",
            "Precision: 0.0\n",
            "Recall   : 0.0\n",
            "F1-score : 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00         2\n",
            "\n",
            "    accuracy                           1.00         2\n",
            "   macro avg       1.00      1.00      1.00         2\n",
            "weighted avg       1.00      1.00      1.00         2\n",
            "\n",
            "\n",
            "----- Tuned Random Forest -----\n",
            "Accuracy : 0.0\n",
            "Precision: 0.0\n",
            "Recall   : 0.0\n",
            "F1-score : 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       2.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "\n",
            "    accuracy                           0.00       2.0\n",
            "   macro avg       0.00      0.00      0.00       2.0\n",
            "weighted avg       0.00      0.00      0.00       2.0\n",
            "\n",
            "\n",
            "✅ Best model saved as 'best_titanic_model.pkl'\n"
          ]
        }
      ],
      "source": [
        "# 1. Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 2. Load dataset\n",
        "df = pd.read_csv(\"file.csv\")\n",
        "\n",
        "# 3. Clean column names\n",
        "df.columns = df.columns.str.strip()\n",
        "print(\"Available columns:\", df.columns.tolist())\n",
        "\n",
        "# 4. Set correct target for Titanic dataset\n",
        "target_column = 'survived'\n",
        "print(\"✅ Using target column:\", target_column)\n",
        "\n",
        "# 5. Check and display data info\n",
        "print(df.head())\n",
        "print(df.info())\n",
        "print(df.describe())\n",
        "print(\"Missing values:\\n\", df.isnull().sum())\n",
        "print(\"Duplicates:\", df.duplicated().sum())\n",
        "\n",
        "# 6. Handle missing values (basic approach — improve later if needed)\n",
        "df['age'].fillna(df['age'].median(), inplace=True)\n",
        "df['embarked'].fillna(df['embarked'].mode()[0], inplace=True)\n",
        "\n",
        "# 7. Preprocess features and target\n",
        "X = df.drop(target_column, axis=1)\n",
        "y = df[target_column]\n",
        "\n",
        "# Encode categorical variables\n",
        "X = pd.get_dummies(X, drop_first=True)\n",
        "\n",
        "# Scale features\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train/Test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 8. Define models\n",
        "models = {\n",
        "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
        "    \"Decision Tree\": DecisionTreeClassifier(),\n",
        "    \"Random Forest\": RandomForestClassifier(),\n",
        "    \"SVM\": SVC(),\n",
        "    \"Naive Bayes\": GaussianNB()\n",
        "}\n",
        "\n",
        "# 9. Evaluation function\n",
        "def evaluate_model(name, model):\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    print(f\"\\n----- {name} -----\")\n",
        "    print(\"Accuracy :\", accuracy_score(y_test, y_pred))\n",
        "    print(\"Precision:\", precision_score(y_test, y_pred, zero_division=0))\n",
        "    print(\"Recall   :\", recall_score(y_test, y_pred, zero_division=0))\n",
        "    print(\"F1-score :\", f1_score(y_test, y_pred, zero_division=0))\n",
        "    print(classification_report(y_test, y_pred, zero_division=0))\n",
        "\n",
        "# 10. Evaluate all models\n",
        "for name, model in models.items():\n",
        "    evaluate_model(name, model)\n",
        "\n",
        "# 11. Hyperparameter tuning - Random Forest\n",
        "param_dist = {\n",
        "    'n_estimators': [50, 100, 150],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 5, 10]\n",
        "}\n",
        "\n",
        "random_search = RandomizedSearchCV(\n",
        "    RandomForestClassifier(random_state=42),\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,\n",
        "    scoring='f1',\n",
        "    cv=5,\n",
        "    random_state=42\n",
        ")\n",
        "random_search.fit(X_train, y_train)\n",
        "best_rf = random_search.best_estimator_\n",
        "\n",
        "# 12. Final evaluation\n",
        "evaluate_model(\"Tuned Random Forest\", best_rf)\n",
        "\n",
        "# 13. Save best model\n",
        "joblib.dump(best_rf, \"best_titanic_model.pkl\")\n",
        "print(\"\\n✅ Best model saved as 'best_titanic_model.pkl'\")\n"
      ]
    }
  ]
}